<!DOCTYPE html>
<html lang="en">


<head>

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="MiLeTs 2020, 6th SIGKDD Workshop on Mining and Learning from Time Series (MiLeTS), co-located with KDD 2020, San Diego, United States">
    <meta property="og:image" content="https://kdd-milets.github.io/milets2020/img/thumbnail.jpg">
    <meta property="og:type" content="website" />
    <meta property="og:title" content="The 6th SIGKDD Mining and Learning from Time Series Workshop">
    <meta property="og:description" content="6th SIGKDD Workshop on Mining and Learning from Time Series (MiLeTS)">


    <title>The 6th Mining and Learning from Time Series Workshop</title>

    <!-- Bootstrap Core CSS -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

    <!-- Custom CSS -->
    <link href="css/agency.css?v=3" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Montserrat:400,700" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Kaushan+Script' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Roboto+Slab:400,100,300,700' rel='stylesheet' type='text/css'>

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-114495477-1"></script>
    <script>
        window.dataLayer = window.dataLayer || [];

        function gtag() {
            dataLayer.push(arguments);
        }

        gtag('js', new Date());

        gtag('config', 'UA-114495477-1');
    </script>


</head>

<body id="page-top" class="index">

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-fixed-top">
        <div class="container">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>

            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li class="hidden">
                        <a href="#page-top"></a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#introduction">Intro</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#keynote">Keynotes</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#call">CFP</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#program">Program</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#dates">Dates</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#organization">Organizers</a>
                    </li>
                    <li>
                        <a class="page-scroll" href="#program_committee">PC</a>
                    </li>
                    <li>
                        <a href="https://milets19.github.io" target="_blank">MiLeTS '19</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container-fluid -->
    </nav>

    <!-- Header -->
    <header>
        <div class="container">
            <div class="intro-text">
                <div class="intro-lead-in">Held in conjunction with <a href="http://www.kdd.org/kdd2020/" target=_blank>KDD'20</a><br/> Aug 24th, 2020 - San Diego, California, USA
                </div>
                <div class="intro-heading">6th Workshop on <br/>Mining and Learning from Time Series</div>
            </div>
        </div>
    </header>

    <!-- Introduction Section -->
    <section id="introduction">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Introduction</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row text-justify">
                <div class="col-md-12">
                    <p class="large text-muted">

                        Time series data are ubiquitous. In domains as diverse as finance, entertainment, transportation and health care, we observe a fundamental shift away from parsimonious, infrequent measurement to nearly continuous monitoring and recording. Rapid advances
                        in diverse sensing technologies, ranging from remote sensors to wearables and social sensing, are generating a rapid growth in the size and complexity of time series archives. Thus, although time series analysis has been studied
                        extensively, its importance only continues to grow. What is more, modern time series data pose significant challenges to existing techniques (e.g., irregular sampling in hospital records and spatiotemporal structure in climate
                        data). Finally, time series mining research is challenging and rewarding because it bridges a variety of disciplines and demands interdisciplinary solutions. Now is the time to discuss the next generation of temporal mining algorithms.
                        The focus of MiLeTS workshop is to synergize the research in this area and discuss both new and open problems in time series analysis and mining. The solutions to these problems may be algorithmic, theoretical, statistical, or
                        systems-based in nature. Further, MiLeTS emphasizes applications to high impact or relatively new domains, including but not limited to biology, health and medicine, climate and weather, road traffic, astronomy, and energy.
                        <br/> The MiLeTS workshop will discuss a broad variety of topics related to time series, including:
                    </p>

                    <ul class="large text-muted">
                        <li>Time series pattern mining and detection, representation, searching and indexing, classification, clustering, prediction, forecasting, and rule mining.
                        </li>
                        <li>Time series with special structure: spatiotemporal (e.g., traffic speeds at different locations), relational (e.g., patients with similar diseases), hierarchical, etc.
                        </li>
                        <li>Time series with sparse or irregular sampling, non-random missing values, and special types of measurement noise or bias.
                        </li>
                        <li>Time series that are multivariate, high-dimensional, heterogeneous, etc., or that possess other atypical properties.
                        </li>
                        <li>Time series analysis using less traditional approaches, such as deep learning and subspace clustering.</li>
                        <li>Privacy preserving time series mining and learning.</li>
                        <li>Online, high-speed learning and mining from streaming time series.</li>
                        <li>Uncertain time series mining.</li>
                        <li>Applications to high impact or relatively new time series domains, such as health and medicine, road traffic, and air quality.
                        </li>
                        <li>New, open, or unsolved problems in time series analysis and mining.
                        </li>
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <!-- Program Section -->



    <!-- Accepted Papers Section -->


    <!-- Call for Papers Section -->
    <section id="call">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Call for Papers</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row text-justify">
                <div class="col-md-12">
                    <p class="large text-muted">
                        Submissions should follow the <a href="https://www.kdd.org/kdd2020/Calls/view/kdd-2020-call-for-research-papers">SIGKDD
                    formatting requirements</a> and will be evaluated using the <a href="https://www.kdd.org/kdd2020/Calls/view/kdd-2020-call-for-research-papers">SIGKDD
                    Research Track evaluation criteria</a>. Preference will be given to papers that are reproducible, and authors are encouraged to share their data and code publicly whenever possible. Submissions are strongly recommended to be <b>no more than 4 pages</b>,
                        excluding references or supplementary materials (all in a single pdf). The appropriateness of using additional pages over the recommended length will be judged by reviewers. All submissions must be in pdf format using theAll submissions
                        must be in pdf format using the workshop template (
                        <a href="template/sample-latex.zip" target="_blank">latex</a>,
                        <a href="template/word-template-anonymous.docx" target="_blank">word</a>). Submissions will be managed via the MiLeTS 2020 EasyChair website: <a href="https://easychair.org/conferences/?conf=milets2020" target="_blank">https://easychair.org/conferences/?conf=milets2020</a>.
                    </p>

                    <p class="large text-muted">
                        <b>Note on <i>open problem</i> submissions:</b> In order to promote new and innovative research on time series, we plan to accept a small number of high quality manuscripts describing <i>open
                    problems</i> in time series analysis and mining. Such papers should provide a clear, detailed description and analysis of a new or open problem that poses a significant challenge to existing techniques, as well as a thorough empirical
                        investigation demonstrating that current methods are insufficient.
                    </p>
                    <p class="large text-muted">
                        <b> COVID-19 Time Series Analysis Special Track:</b> The COVID-19 pandemic is impacting almost everyone worldwide and is expected to have life-altering short and long-term effects. There are many potential applications of time
                        series analysis and mining that can contribute to understanding of this pandemic. We encourage submission of high quality manuscripts describing original problems, time series datasets, and novel solutions for time series analysis
                        and forecasting of COVID-19.
                    </p>

                    <p class="large text-muted">
                        The review process is single-round and double-blind (submission files have to be anonymized). Concurrent submissions to other journals and conferences are acceptable. Accepted papers will be presented as posters during the workshop and list on the website.
                        Besides, a small number of accepted papers will be selected to be presented as contributed talks.
                    </p>

                    <p class="large text-muted">
                        Any questions may be directed to the workshop e-mail address: <a href="mailto:kdd.milets@gmail.com">kdd.milets@gmail.com</a>.

                    </p>
                </div>
            </div>
        </div>
    </section>

    <!-- Program Section -->
    <section id="program" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Schedule</h2>
                    <h3 class="section-subheading text-muted">
                        8:00 AM - 5:00 PM, August 24th, 2020<br>
                    </h3>
                </div>
            </div>


            <div class="row">
                <div class="col-lg-1 text-left">
                    &nbsp;
                </div>
                <div class="col-lg-10 text-left ">
                    <h3>MORNING SESSION</h3>
                    <p>08:00-08:10 Opening remarks</p>
                    <p>08:10-09:10 Keynote Talk, Dr. Mihaela van der Schaar</p>
                    <p>09:15-10:15 Keynote Talk</p>
                    <ul>
                        <li><strong>Think Globally, Act Locally: A Deep Neural Network Approach to High-Dimensional Time Series Forecasting</strong>, <em>Dr. Inderjit S. Dhillon</em></li>
                    </ul>
                    <p>10:15-10:45 Coffee Break</p>
                    <p>10:45-12:00 Contributed Talks</p>
                    <p>12:00-13:00 Lunch Break</p>

                    <h3>AFTERNOON SESSION</h3>
                    <p>13:00-14:00 Keynote Talk</p>
                    <ul>
                        <li><strong>The Efficient Transformer </strong>, <em>Dr. Łukasz Kaiser</em></li>
                    </ul>
                    <p>14:00-14:30 Poster Highlights</p>
                    <p>14:30-15:00 Coffee Break</p>
                    <p>15:00-16:00 Keynote Talk, Dr. Nikunj Oza</p>
                    <p>16:00-16:45 Poster Session</p>
                    <p>16:45-17:00 Concluding Remarks</p>
                </div>

                <div class="col-lg-1 text-left">
                    &nbsp;
                </div>
            </div>
        </div>
    </section>

    <!-- Keynote Section -->

    <section id="keynote">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Speakers</h2>
                </div>

            </div>

            <!-- Inderjit S. Dhillon -->
            <div class="row speakers">
                <div class="col-sm-4">
                    <div class="team-member">
                        <a href="https://www.cs.utexas.edu/~inderjit/" target="_blank">
                            <img src="img/inderjit_dhillon.jpg" style="height: 240px; width:240px;" class="img-responsive img-circle" alt="Inderjit S. Dhillon">
                        </a>
                        <h4><a href="https://www.cs.utexas.edu/~inderjit/" target="_blank">Inderjit S. Dhillon</a></h4>
                        <p class="text-muted">Professor, Amazon Fellow<br/>University of Texas at Austin & Amazon</p>

                    </div>
                </div>

                <div class="col-sm-8 text-justify">
                    <h3> Think Globally, Act Locally: A Deep Neural Network Approach to High-Dimensional Time Series Forecasting </h3>
                    <p>
                        Forecasting high-dimensional time series plays a crucial role in many applications such as demand forecasting and financial predictions. Modern datasets can have millions of correlated time-series that evolve together, i.e they are extremely high dimensional
                        (one dimension for each individual time-series). There is a need for exploiting global patterns and coupling them with local calibration for better prediction. However, most recent deep learning approaches in the literature are
                        one-dimensional, i.e, even though they are trained on the whole dataset, during prediction, the future forecast for a single dimension mainly depends on past values from the same dimension. In this paper, we seek to correct this
                        deficiency and propose DeepGLO, a deep forecasting model which thinks globally and acts locally. In particular, DeepGLO is a hybrid model that combines a global matrix factorization model regularized by a temporal convolution network,
                        along with another temporal network that can capture local properties of each time-series and associated covariates. Our model can be trained effectively on high-dimensional but diverse time series, where different time series
                        can have vastly different scales, without a priori normalization or rescaling. Empirical results demonstrate that DeepGLO can outperform state-of-the-art approaches; for example, we see more than 25% improvement in WAPE over other
                        methods on a public dataset that contains more than 100K-dimensional time series. This is joint work with Rajat Sen and Hsiang-Fu Yu.
                    </p>
                    <b>Bio</b><br> Dr. Inderjit Dhillon is the Gottesman Family Centennial Professor of Computer Science and Mathematics at UT Austin, where he is also the Director of the ICES Center for Big Data Analytics. Currently he is on leave from
                    UT Austin and heads the Amazon Research Lab in Berkeley, California, where he is developing and deploying state-of-the-art machine learning methods for Amazon Search. His main research interests are in big data, machine learning, network
                    analysis, linear algebra and optimization. He received his B.Tech. degree from IIT Bombay, and Ph.D. from UC Berkeley. Inderjit has received the following awards: the ICES Distinguished Research Award, the SIAM Outstanding Paper Prize,
                    the Moncrief Grand Challenge Award, the SIAM Linear Algebra Prize, the University Research Excellence Award, and the NSF Career Award. He has published over 175 journal and conference papers, and has served on the Editorial Board of
                    the Journal of Machine Learning Research, the IEEE Transactions of Pattern Analysis and Machine Intelligence, Foundations and Trends in Machine Learning and the SIAM Journal for Matrix Analysis and Applications. Inderjit is actively
                    involved with industry. He is currently an Amazon Fellow at A9/Amazon, where he is developing and deploying state-of-the-art machine learning methods in Amazon search. Prior to joining Amazon, Inderjit worked as a quantitative analyst
                    at a hedge fund, Voleon, which does systematic machine learning statistical arbitrage. In the past, Inderjit has been a consultant for Walmart Labs, Sabre Inc, Yahoo!, Syncata, and Neonyoyo. Inderjit is an ACM Fellow, an IEEE Fellow,
                    a SIAM Fellow and an AAAS Fellow.
                </div>
            </div>

            <!-- Lukasz Kaiser -->
            <div class="row speakers">
                <div class="col-sm-4">
                    <div class="team-member">
                        <a href="https://research.google/people/LukaszKaiser/" target="_blank">
                            <img src="img/lukasz_kaiser.jpg" style="height: 240px; width:240px;" class="img-responsive img-circle" alt="Łukasz Kaiser">
                        </a>
                        <h4><a href="https://research.google/people/LukaszKaiser/" target="_blank">Łukasz Kaiser</a></h4>
                        <p class="text-muted"> Staff Research Scientist<br/>Google Brain & CNRS</p>

                    </div>
                </div>

                <div class="col-sm-8 text-justify">
                    </p>
                    <h3>Reformer: The Efficient Transformer </h3>
                    <p>
                    </p>
                    Transformer models have been used in a variety of fields and yield great results on many NLP tasks. But between the BERT, GPT-2, and many other variants, they can be inefficient and it can be hard to apply them. I will introduce a new efficient variant
                    of Transformer called the Reformer. I'll take you through the code that implements it and I will show how it runs at high efficiency and addresses the main problems or high memory use and low performance on long sequences that limited
                    the use of some Transformers before. I will finish with new applications of Reformer that open up.
                    <br>
                    <br>
                    <b>Bio</b><br> Dr. Łukasz Kaiser joined Google in 2013 and is currently a staff Research Scientist in the Google Brain Team in Mountain View, where he works on fundamental aspects of deep learning and natural language processing. He
                    has co-designed state-of-the-art neural models for machine translation, parsing and other algorithmic and generative tasks and co-authored the TensorFlow system, the Tensor2Tensor and Trax libraries and the Transformer model. Before
                    joining Google, Lukasz was a tenured researcher at University Paris Diderot and worked on logic and automata theory. He received his PhD from RWTH Aachen University in 2008 and his MSc from the University of Wroclaw, Poland.
                    </p>
                </div>
            </div>

            <!-- Mihaela van der Schaar -->
            <div class="row speakers">
                <div class="col-sm-4">
                    <div class="team-member">
                        <a href="https://www.vanderschaar-lab.com/prof-mihaela-van-der-schaar/" target="_blank">
                            <img src="img/mihaela_schaar.jpg" style="height: 240px; width:240px;" class="img-responsive img-circle" alt="Mihaela van der Schaar">
                        </a>
                        <h4><a href="https://www.vanderschaar-lab.com/prof-mihaela-van-der-schaar/" target="_blank">Mihaela van der Schaar</a></h4>
                        <p class="text-muted"> Professor <br/>University of Cambridge, UCLA, The Alan Turing Institute</p>

                    </div>
                </div>

                <div class="col-sm-8 text-justify">
                    </p>
                    <br>
                    <b>Bio</b><br> Dr. Mihaela van der Schaar is the John Humphrey Plummer Professor of Machine Learning, Artificial Intelligence and Medicine at the University of Cambridge, a Fellow at The Alan Turing Institute in London, and a Chancellor’s
                    Professor at UCLA. Mihaela was elected IEEE Fellow in 2009. She has received numerous awards, including the Oon Prize on Preventative Medicine from the University of Cambridge (2018), a National Science Foundation CAREER Award (2004),
                    3 IBM Faculty Awards, the IBM Exploratory Stream Analytics Innovation Award, the Philips Make a Difference Award and several best paper awards, including the IEEE Darlington Award. Mihaela’s work has also led to 35 USA patents (many
                    widely cited and adopted in standards) and 45+ contributions to international standards for which she received 3 International ISO (International Organization for Standardization) Awards. In 2019, she was identified by National Endowment
                    for Science, Technology and the Arts as the most-cited female AI researcher in the UK. She was also elected as a 2019 “Star in Computer Networking and Communications” by N²Women. Her research expertise span signal and image processing,
                    communication networks, network science, multimedia, game theory, distributed systems, machine learning and AI. Mihaela’s current research focus is on machine learning, AI and operations research for healthcare and medicine.

                    </p>
                </div>
            </div>

            <!-- Nikunj Oza -->
            <div class="row speakers">
                <div class="col-sm-4">
                    <div class="team-member">
                        <a href="https://c3.nasa.gov/dashlink/members/27/" target="_blank">
                            <img src="img/nikunj_oza.jpg" style="height: 240px; width:240px;" class="img-responsive img-circle" alt="Nikunj Oza">
                        </a>
                        <h4><a href="https://c3.nasa.gov/dashlink/members/27/" target="_blank">Nikunj Oza</a></h4>
                        <p class="text-muted">Leader of Data Sciences Group<br/>NASA Ames Research Center</p>

                    </div>
                </div>

                <div class="col-sm-8 text-justify">
                    </p>
                    <br>
                    <b>Bio</b><br> Dr. Nikunj Oza is the leader of the Data Sciences Group at NASA Ames Research Center. He also leads a NASA project team, which applies machine learning to aviation safety and operations problems. Dr. Oza’s 50+ research
                    papers represent his research interests, which include data mining, machine learning, ensemble learning, anomaly detection, and their applications to Aeronautics and Earth Science. He received the Arch T. Colwell Award for co-authoring
                    one of the five most innovative technical papers selected from 3300+ SAE technical papers in 2005. His data mining team received the 2018 and 2019 NASA Honor Awards and the 2010 NASA Aeronautics Research Mission Directorate Associate
                    Administrator¹s Award. In 2019, he was named by Cognilytica as one of 50 key people in the US government working to move the adoption of AI forward across the industry. He is an Associate Editor for the peer-reviewed journal Information
                    Fusion (Elsevier) and has served as organizer, senior program committee member, and program committee member of several data mining and machine learning conferences. He received his B.S. in Mathematics with Computer Science from MIT
                    in 1994, and M.S. (in 1998) and Ph.D. (in 2001) in Computer Science from the University of California at Berkeley.
                    </p>
                </div>
            </div>




            <!-- <div class="row">
            <div class="col-lg-12 text-center">
                <h3 class="section-subheading text-muted">More keynote speakers will be announced ...</h3>
            </div>
        </div> -->


        </div>

    </section>



    <!-- Accepted Papers Section -->
    <section id="papers" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Accepted Papers</h2>
                    <!--h3 class="section-heading">TBA</h3> -->
                </div>
            </div>

            <div class="row">
                <div class="col-lg-1 text-justify">
                    &nbsp;
                </div>
                <div class="col-lg-10 text-justify">

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_7.pdf" target="_blank">
       The Effectiveness of Discretization in Forecasting: An Empirical Study on Neural Time Series Models
    </a> Stephan Rabanser, Tim Januschowski, Valentin Flunkert, David Salinas and Jan Gasthaus
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_17.pdf" target="_blank">
        Driver2vec: Driver Identification from Automotive Data
        </a> Jingbo Yang, Ruge Zhao, Meixian Zhu, Jaka Sodnik, David Hallac and Jure Leskovec
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_16.pdf" target="_blank">
        Improving Robustness on Seasonality-Heavy Multivariate Time Series Anomaly Detection
        </a> Farzaneh Khoshnevisan, Zhewen Fan and Vitor Carvalho
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_11.pdf" target="_blank">
        Detection of Environment Transitions in Time Series Data for Responsive Science
        </a> Ameya Daigavane, Kiri Wagstaff, Gary Doran, Corey Cochrane, Caitriona Jackman and Abigail Rymer
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_20.pdf" target="_blank">
        Instance Explainable Temporal Network For Multivariate Timeseries
        </a> Naveen Madiraju and Homa Karimabadi
                    </p>
                </div>
                <div class="col-lg-1 text-justify">
                    &nbsp;
                </div>

            </div>

        </div>
    </section>


    <section id="posters" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Accepted Posters</h2>
                    <!-- <h3 class="section-heading">TBA</h3> -->

                </div>
            </div>

            <div class="row">
                <div class="col-lg-1 text-justify">
                    &nbsp;
                </div>
                <div class="col-lg-10 text-justify">


                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_6.pdf" target="_blank">
       Modality Selection for Classification on Time-series Data
    </a> Murchana Baruah and Bonny Banerjee
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_8.pdf" target="_blank">
       Machine Learning Methods for Predictive Maintenance of Multifunctional Printers
    </a> Wojciech Indyk, Zuzana Neverilova and Jakub Valcik
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_1.pdf" target="_blank">
       Towards Deep Unsupervised Representation Learning from Accelerometer Time Series for Animal Activity Recognition
    </a> Jacob Kamminga, Viet Duc Le, Nirvana Meratnia and Paul Havinga
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_3.pdf" target="_blank">
       Statistical Evaluation of Anomaly Detectors for Sequences
    </a> Erik Scharwächter and Emmanuel Müller
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_12.pdf" target="_blank">
       A framework for incorporating  data acquisition cost in predictive time series models
    </a> Adrian Stetco, Razvan Mosincat, Goran Nenadic and John Keane
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_18.pdf" target="_blank">
       PastProp-RNN: improved predictions of the future by correcting the past
    </a> André Baptista, Yassine Baghoussi, Carlos Soares, Miguel Arantes and João Mendes-Moreira
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_5.pdf" target="_blank">
       RobustTAD: Robust Time Series Anomaly Detection via Decomposition and Convolutional Neural Networks
    </a> Jingkun Gao, Xiaomin Song, Qingsong Wen, Pichao Wang, Liang Sun and Huan Xu
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_13.pdf" target="_blank">
       Forecasting Hierarchical Time Series with a Regularized Embedding Space
    </a> Jeffrey Gleason
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_15.pdf" target="_blank">
       Towards Automating Time Series Analysis for Paleogeosciences
    </a> Deborah Khider, Pratheek Athreya, Varun Ratnakar, Yolanda Gil, Feng Zhu, Myron Kwan and Julien Emile-Geay
                    </p>

                    <p class="row large text-muted">
                        <a href="papers/MiLeTS2020_paper_19.pdf" target="_blank">
       Interpreting Deep Temporal Neural Networks by Selective Visualization of Internally Activated Nodes
    </a> Sohee Cho, Wonjoon Chang, Ginkyeng Lee and Jaesik Choi
                    </p> ​

                    <!-- End Poster List -->

                </div>
                <div class="col-lg-1 text-justify">
                    &nbsp;
                </div>

            </div>
        </div>

    </section>

    <!-- Dates Section -->
    <section id="dates" class="bg-mid-gray">
        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Key Dates</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>
            <div class="row">
                <div class="col-lg-4 text-left">
                    &nbsp;
                </div>
                <div class="col-lg-8 text-left">
                    <div class="col-md-12">
                        <!--<p class="large text-muted">-->
                        <!--<b>Paper Submission Deadline:</b> <strike class="text-muted">TBD</strike>-->
                        <!--</p>-->
                        <p class="large text-muted">
                            <b>Paper Submission Deadline:</b> <span style="text-decoration: line-through;" class="text-muted">June 10th</span> June 20th, 2020, 11:59PM Alofi Time
                        </p>
                        <p class="large text-muted">
                            <b>Author Notification:</b> <span>July 13th, 2020</span>
                        </p>
                        <p class="large text-muted">
                            <b>Camera Ready Version:</b> July 27th, 2020
                        </p>
                        <p class="large text-muted">
                            <b>Video Submission:</b> July 30th, 2020
                        </p>
                        <p class="large text-muted">
                            <b>Workshop:</b> August 24th, 2020
                        </p>
                    </div>
                </div>
            </div>
        </div>
    </section>

    <!-- Organization Section -->
    <section id="organization">

        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center" style="padding-bottom: 20px;">
                    <h2 class="section-heading">Workshop Organizers & Steering Committee</h2>
                    <!--h3 class="section-subheading text-muted">Lorem ipsum dolor sit amet consectetur.</h3-->
                </div>
            </div>

            <div class="row">
                <div class="col-sm-1">
                    &nbsp;
                </div>

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/sanjay.png" class="img-responsive img-circle" alt="">
                        <h4><a href="https://sanjayp.is.umbc.edu/">Sanjay Purushotham</a></h4>
                        <p class="text-muted">University of Maryland, Baltimore County</p>
                    </div>
                </div>
                <div class="col-sm-2">
                    &nbsp;
                </div>

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/roseyu.jpg" class="img-responsive img-circle" alt="">
                        <h4><a href="http://roseyu.com/">Qi (Rose) Yu</a></h4>
                        <p class="text-muted">University of California, San Diego</p>
                    </div>
                </div>

                <div class="col-sm-2">
                    &nbsp;
                </div>

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/yaguangli.jpg" class="img-responsive img-circle" alt="">
                        <h4><a href="http://www-scf.usc.edu/~yaguang/">YaGuang Li</a></h4>
                        <p class="text-muted">Google</p>
                    </div>
                </div>
            </div>

            <div class="row">

                <div class="col-sm-1">
                    &nbsp;
                </div>


                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/eamonn.jpg" class="img-responsive img-circle" alt="">
                        <h4><a href="http://www.cs.ucr.edu/~eamonn/">Eamonn Keogh</a></h4>
                        <p class="text-muted">University of California Riverside</p>
                    </div>
                </div>

                <div class="col-sm-2">
                    &nbsp;
                </div>

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/yanliu.jpg" class="img-responsive img-circle" alt="">
                        <h4><a href="http://www-bcf.usc.edu/~liu32/">Yan Liu</a></h4>
                        <p class="text-muted">University of Southern California</p>
                    </div>
                </div>


                <div class="col-sm-2">
                    &nbsp;
                </div>

                <div class="col-sm-2">
                    <div class="team-member">
                        <img src="img/mueen.jpg" class="img-responsive img-circle" alt="">
                        <h4><a href="http://www.cs.unm.edu/~mueen/">Abdullah Mueen </a></h4>
                        <p class="text-muted">University of New Mexico</p>
                    </div>
                </div>

                <div class="col-sm-1">
                    &nbsp;
                </div>
            </div>


        </div>
    </section>


    <section id="program_committee">

        <div class="container">
            <div class="row">
                <div class="col-lg-12 text-center">
                    <h2 class="section-heading">Program Committee</h2>
                </div>
            </div>
            <div class="row">
                <div class="col-lg-2"></div>
                <div class="col-lg-8">
                    <ul class="large">
                        <li>Zhengping Che, Didi Chuxing</li>
                        <li>Dehua Cheng, Facebook AI </li>
                        <li>Jing Dai, Google</li>
                        <li>Abhishek Mukherji, Cisco Systems</li>
                        <li>Sungyong Seo, University of Southern California </li>
                        <li>Xingjian Shi, Amazon Web Sevices</li>
                        <li>Michael Tsang, University of Southern California</li>
                        <li>Zheng Wang, Didi Chuxing</li>
                        <li>Qingsong Wen, Alibaba DAMO Academy</li>
                        <li>Bin Yang, Aalborg University</li>
                        <li>Scott Yang, New York University</li>
                        <li>Michael Yeh, Visa Research</li>
                        <li>Jiayu Zhou, Michigan State University</li>
                    </ul>
                </div>
                <div class="col"></div>
            </div>

        </div>
    </section>


    <!-- jQuery -->
    <script src="js/jquery.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="js/bootstrap.min.js"></script>

    <!-- Plugin JavaScript -->
    <script src="http://cdnjs.cloudflare.com/ajax/libs/jquery-easing/1.3/jquery.easing.min.js"></script>
    <script src="js/classie.js"></script>
    <script src="js/cbpAnimatedHeader.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/contact_me.js"></script>

    <!-- Custom Theme JavaScript -->
    <script src="js/agency.js"></script>

</body>

</html>